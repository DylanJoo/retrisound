---
config_file: configs/llama3.1-metric.yaml
retriever_name_or_path: facebook/contriever-msmarco
generator_name_or_path: meta-llama/Meta-Llama-3.1-8B-Instruct
attn_implementation: flash_attention_2
train_file: /home/dju/datasets/asqa/ASQA.json
corpus_file: /home/dju/datasets/wikipedia_split/
retrieval_file: /home/dju/datasets/asqa/train_data_bm25-top100.run
dataloader_num_workers: 16
learning_rate: 0.00001
lr_scheduler_type: linear
warmup_ratio: 0.1
weight_decay: 0.
report_to: wandb
output_dir: /ivi/ilps/personal/dju/checkpoints/adarag_8B
save_steps: 1000
logging_steps: 1
total_episodes: 10000
n_contexts: 5
n_max_candidates: 30
depth: 30
n_max_segments: 5
num_steps: 5
reward_function: metric
cont_coef: 0.0
per_device_train_batch_size: 1
gradient_accumulation_steps: 2
num_mini_batches: 1
quick_test: true
low_cpu_mem_usage: true
deepspeed: configs/stage3_no_offloading_accelerate.conf
